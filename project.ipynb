{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":69160,"sourceType":"modelInstanceVersion","modelInstanceId":57690,"modelId":79606}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:02:06.367000Z","iopub.execute_input":"2025-11-23T10:02:06.367813Z","iopub.status.idle":"2025-11-23T10:02:06.377230Z","shell.execute_reply.started":"2025-11-23T10:02:06.367775Z","shell.execute_reply":"2025-11-23T10:02:06.376489Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/qwen2/transformers/7b-instruct/1/model.safetensors.index.json\n/kaggle/input/qwen2/transformers/7b-instruct/1/model-00003-of-00004.safetensors\n/kaggle/input/qwen2/transformers/7b-instruct/1/config.json\n/kaggle/input/qwen2/transformers/7b-instruct/1/merges.txt\n/kaggle/input/qwen2/transformers/7b-instruct/1/LICENSE\n/kaggle/input/qwen2/transformers/7b-instruct/1/model-00001-of-00004.safetensors\n/kaggle/input/qwen2/transformers/7b-instruct/1/README.md\n/kaggle/input/qwen2/transformers/7b-instruct/1/tokenizer.json\n/kaggle/input/qwen2/transformers/7b-instruct/1/vocab.json\n/kaggle/input/qwen2/transformers/7b-instruct/1/tokenizer_config.json\n/kaggle/input/qwen2/transformers/7b-instruct/1/model-00004-of-00004.safetensors\n/kaggle/input/qwen2/transformers/7b-instruct/1/model-00002-of-00004.safetensors\n/kaggle/input/qwen2/transformers/7b-instruct/1/generation_config.json\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#!pip install --quiet transformers sentence-transformers tqdm accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:02:06.634877Z","iopub.execute_input":"2025-11-23T10:02:06.635136Z","iopub.status.idle":"2025-11-23T10:02:06.638797Z","shell.execute_reply.started":"2025-11-23T10:02:06.635111Z","shell.execute_reply":"2025-11-23T10:02:06.638163Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#!pip install --quiet chromadb gradio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:02:06.639532Z","iopub.execute_input":"2025-11-23T10:02:06.639863Z","iopub.status.idle":"2025-11-23T10:02:06.650441Z","shell.execute_reply.started":"2025-11-23T10:02:06.639846Z","shell.execute_reply":"2025-11-23T10:02:06.649804Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"#!pip install protobuf==3.20.3 --quiet --force-reinstall","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:02:06.652353Z","iopub.execute_input":"2025-11-23T10:02:06.652574Z","iopub.status.idle":"2025-11-23T10:02:06.662370Z","shell.execute_reply.started":"2025-11-23T10:02:06.652558Z","shell.execute_reply":"2025-11-23T10:02:06.661736Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"#!pip install textstat","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!pip install --upgrade datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:02:06.688228Z","iopub.execute_input":"2025-11-23T10:02:06.688399Z","iopub.status.idle":"2025-11-23T10:02:06.698529Z","shell.execute_reply.started":"2025-11-23T10:02:06.688386Z","shell.execute_reply":"2025-11-23T10:02:06.697795Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import torch\nprint(\"GPU0 free:\", torch.cuda.mem_get_info(0)[0] / 1024**3, \"GB\")\nprint(\"GPU1 free:\", torch.cuda.mem_get_info(1)[0] / 1024**3, \"GB\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:02:06.378466Z","iopub.execute_input":"2025-11-23T10:02:06.378696Z","iopub.status.idle":"2025-11-23T10:02:06.634205Z","shell.execute_reply.started":"2025-11-23T10:02:06.378680Z","shell.execute_reply":"2025-11-23T10:02:06.633595Z"}},"outputs":[{"name":"stdout","text":"GPU0 free: 14.6407470703125 GB\nGPU1 free: 14.6407470703125 GB\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:02:06.663152Z","iopub.execute_input":"2025-11-23T10:02:06.663983Z","iopub.status.idle":"2025-11-23T10:02:06.673653Z","shell.execute_reply.started":"2025-11-23T10:02:06.663966Z","shell.execute_reply":"2025-11-23T10:02:06.672969Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import os, json, torch, time\nfrom datasets import load_dataset\nimport chromadb\nfrom chromadb.utils import embedding_functions\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport gradio as gr\nfrom typing import List, Tuple, Dict\n\n# Paths\nCHROMA_PATH = \"/kaggle/working/chroma_db\"\nQWEN_PATH = \"/kaggle/input/qwen2/transformers/7b-instruct/1\"  # Change if different\nCOLLECTION_NAME = \"health_rag_collection\"\n\n# Models\nEMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Agent settings\nTOPK_INITIAL = 5\nTOPK_EXPANDED = 10\nCONF_THRESHOLD = 0.75\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:02:06.674352Z","iopub.execute_input":"2025-11-23T10:02:06.674532Z","iopub.status.idle":"2025-11-23T10:02:06.687547Z","shell.execute_reply.started":"2025-11-23T10:02:06.674517Z","shell.execute_reply":"2025-11-23T10:02:06.686803Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Core datasets\nds_health = load_dataset(\"katielink/healthsearchqa\", \"all_data\")       # Layman queries\nds_mediqa = load_dataset(\"medarc/consumer_health_questions\")               # Patient-oriented answers\nds_flash = load_dataset(\"medalpaca/medical_meadow_medical_flashcards\")\nprint(ds_flash['train'][0])\n\nprint(\"Datasets Loaded:\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:02:06.699334Z","iopub.execute_input":"2025-11-23T10:02:06.699573Z","iopub.status.idle":"2025-11-23T10:02:11.817582Z","shell.execute_reply.started":"2025-11-23T10:02:06.699550Z","shell.execute_reply":"2025-11-23T10:02:11.816985Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5c3ca7ffbeb480b89ba0707e53c532e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"all.csv: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcb7224e86ea47cd8018bf898a0af852"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/4436 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"837f51cf55154edfbab3f47efc6f9558"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/726 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87711fcca1094f39bf4ac28a6a7c506d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00001-75c4fb7f8b48a5(‚Ä¶):   0%|          | 0.00/263k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afd92906791448c7be1e159f5e698e29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/validation-00000-of-00001-5c00689bb(‚Ä¶):   0%|          | 0.00/17.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd489b9eba6d4e1b895928308f6aedb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/test-00000-of-00001-e5b09505424159d(‚Ä¶):   0%|          | 0.00/47.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c5d40cdcb9a41abb9ecf024387459c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2eece03f7f7477da0a4248fd11ac165"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/50 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6404ea6362c4e68ac18fd1391f3fb7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/150 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23ec8d25aa9245cfbaf1ddf8850b91f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e64dcabcc47455c8961a251e8504fd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"medical_meadow_wikidoc_medical_flashcard(‚Ä¶):   0%|          | 0.00/17.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc64c28921ff4edebbd2d0da6b07aa0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/33955 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d7d88fa23d840e9929818e83ca8e25b"}},"metadata":{}},{"name":"stdout","text":"{'input': 'What is the relationship between very low Mg2+ levels, PTH levels, and Ca2+ levels?', 'output': 'Very low Mg2+ levels correspond to low PTH levels which in turn results in low Ca2+ levels.', 'instruction': 'Answer this question truthfully'}\nDatasets Loaded:\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"client = chromadb.PersistentClient(path=CHROMA_PATH)\nembed_fn = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=EMBED_MODEL)\ncollection = client.get_or_create_collection(name=COLLECTION_NAME, embedding_function=embed_fn)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:02:11.818354Z","iopub.execute_input":"2025-11-23T10:02:11.818591Z","iopub.status.idle":"2025-11-23T10:02:39.171788Z","shell.execute_reply.started":"2025-11-23T10:02:11.818573Z","shell.execute_reply":"2025-11-23T10:02:39.171018Z"}},"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763892134.891983     135 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763892134.935505     135 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af267bbfd43248738269fcc8ea3f229c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6af54d55bea4ea79942cfe51d4fc437"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7545094095b44058a9b58305a5c817d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a042f48ff4db4b748f38af62938edfc2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ef8589ca31d413c96e1e0715054db5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66d74bdc6535456d94193e52d3896a87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b99155604a044211b84d1afd26bd4aa8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa55b35cfa7c4d608e64eaabf8559642"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7b574aea69a4dbdaa46a49adb3dfae4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2344ba0ce9648be8785d13b62db01d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5d5786150064c3c93012b45df075d08"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"print(\"HealthSearch example:\", ds_health['train'][0])\nprint(\"MediQA/consumer example:\", ds_mediqa['train'][0])\nprint(\"Flashcard example:\", ds_flash['train'][0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:02:39.172564Z","iopub.execute_input":"2025-11-23T10:02:39.172842Z","iopub.status.idle":"2025-11-23T10:02:39.178569Z","shell.execute_reply.started":"2025-11-23T10:02:39.172822Z","shell.execute_reply":"2025-11-23T10:02:39.177658Z"}},"outputs":[{"name":"stdout","text":"HealthSearch example: {'id': 1.0, 'question': 'Are benign brain tumors serious?'}\nMediQA/consumer example: {'id': 0, 'inputs': 'SUBJECT: who and where to get cetirizine - D MESSAGE: I need/want to know who manufscturs Cetirizine. My Walmart is looking for a new supply and are not getting the recent', 'target': 'Who manufactures cetirizine?'}\nFlashcard example: {'input': 'What is the relationship between very low Mg2+ levels, PTH levels, and Ca2+ levels?', 'output': 'Very low Mg2+ levels correspond to low PTH levels which in turn results in low Ca2+ levels.', 'instruction': 'Answer this question truthfully'}\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"print(\"Chroma collection size:\", collection.count())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:02:39.179405Z","iopub.execute_input":"2025-11-23T10:02:39.179742Z","iopub.status.idle":"2025-11-23T10:02:39.202251Z","shell.execute_reply.started":"2025-11-23T10:02:39.179721Z","shell.execute_reply":"2025-11-23T10:02:39.201549Z"}},"outputs":[{"name":"stdout","text":"Chroma collection size: 0\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"if collection.count() == 0:\n    docs, metas, ids = [], [], []\n    idx = 0  # unique id tracking\n\n    # üîπ 1. Ingest medical Q&A from flashcard dataset\n    for row in ds_flash['train']:\n        text = row.get('output', '')\n        if text and len(text.strip()) > 30:\n            docs.append(text.strip())\n            metas.append({\"source\": \"flashcard_dataset\"})\n            ids.append(str(idx))\n            idx += 1\n        if idx >= 2000: break  # Limit ingestion\n\n    # üîπ 2. Ingest refined patient question dataset\n    for row in ds_mediqa['train']:\n        text = row.get('target', '')  # use cleaned version\n        if text and len(text.strip()) > 30:\n            docs.append(text.strip())\n            metas.append({\"source\": \"consumer_health\"})\n            ids.append(str(idx))\n            idx += 1\n        if idx >= 3500: break  # Combined target cap\n\n    # üöÄ Ingest into ChromaDB\n    collection.add(documents=docs, metadatas=metas, ids=ids)\n    print(f\"üî• Successfully ingested {len(ids)} documents.\")\n\nelse:\n    print(f\"üü¢ ChromaDB already contains {collection.count()} documents.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:02:39.202971Z","iopub.execute_input":"2025-11-23T10:02:39.203234Z","iopub.status.idle":"2025-11-23T10:02:58.853330Z","shell.execute_reply.started":"2025-11-23T10:02:39.203210Z","shell.execute_reply":"2025-11-23T10:02:58.852663Z"}},"outputs":[{"name":"stdout","text":"üî• Successfully ingested 2971 documents.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"print(\"üì¶ Final ChromaDB document count:\", collection.count())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:02:58.856251Z","iopub.execute_input":"2025-11-23T10:02:58.856478Z","iopub.status.idle":"2025-11-23T10:02:58.861859Z","shell.execute_reply.started":"2025-11-23T10:02:58.856462Z","shell.execute_reply":"2025-11-23T10:02:58.861139Z"}},"outputs":[{"name":"stdout","text":"üì¶ Final ChromaDB document count: 2971\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"print(\"üîç Retrieval test:\")\nresults = collection.query(query_texts=[\"diabetes surgery complication\"], n_results=3)\nfor doc in results['documents'][0]:\n    print(\"- \", doc[:150], \"...\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:02:58.862726Z","iopub.execute_input":"2025-11-23T10:02:58.862998Z","iopub.status.idle":"2025-11-23T10:02:58.940508Z","shell.execute_reply.started":"2025-11-23T10:02:58.862974Z","shell.execute_reply":"2025-11-23T10:02:58.939801Z"}},"outputs":[{"name":"stdout","text":"üîç Retrieval test:\n-  What are the treatments for diabetes and can it be reversed? ...\n-  What are the complications of type 1 diabetes? ...\n-  What is the latest research on pancreas transplants for type one diabetes? ...\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(QWEN_PATH)\nmodel = AutoModelForCausalLM.from_pretrained(QWEN_PATH, torch_dtype=\"auto\", device_map=\"auto\")\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:02:58.941265Z","iopub.execute_input":"2025-11-23T10:02:58.941522Z","iopub.status.idle":"2025-11-23T10:05:48.866131Z","shell.execute_reply.started":"2025-11-23T10:02:58.941504Z","shell.execute_reply":"2025-11-23T10:05:48.865498Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a52385ae1a24908bb781ac3269b3ad0"}},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(152064, 3584)\n    (layers): ModuleList(\n      (0-27): 28 x Qwen2DecoderLayer(\n        (self_attn): Qwen2Attention(\n          (q_proj): Linear(in_features=3584, out_features=3584, bias=True)\n          (k_proj): Linear(in_features=3584, out_features=512, bias=True)\n          (v_proj): Linear(in_features=3584, out_features=512, bias=True)\n          (o_proj): Linear(in_features=3584, out_features=3584, bias=False)\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n          (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n          (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n)"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"def chat(system, user, mode=\"answer\", max_tokens=512):\n    # üéØ Choose decoding strategy\n    do_sample = True if mode == \"evaluation\" else False\n    temperature = 0.3 if mode == \"evaluation\" else None\n\n    # üö´ No ellipsis here\n    messages = [\n        {\"role\": \"system\", \"content\": str(system)},\n        {\"role\": \"user\", \"content\": str(user)}\n    ]\n\n    # üëá CORRECT: remove ellipsis and use proper message input\n    text = tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=True\n    )\n\n    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n\n    with torch.no_grad():\n        output = model.generate(\n            **inputs,\n            max_new_tokens=max_tokens,\n            do_sample=do_sample,\n            temperature=temperature,\n            top_p=None  # Disable nucleus sampling if not using sampling mode\n        )\n\n    return tokenizer.decode(\n        output[0, inputs['input_ids'].shape[1]:],\n        skip_special_tokens=True\n    ).strip()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:10:30.712068Z","iopub.execute_input":"2025-11-23T10:10:30.712309Z","iopub.status.idle":"2025-11-23T10:10:30.727463Z","shell.execute_reply.started":"2025-11-23T10:10:30.712288Z","shell.execute_reply":"2025-11-23T10:10:30.726790Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"print(chat(\"You are assistant.\", \"Hello!\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:05:48.873972Z","iopub.execute_input":"2025-11-23T10:05:48.874291Z","iopub.status.idle":"2025-11-23T10:05:50.760247Z","shell.execute_reply.started":"2025-11-23T10:05:48.874258Z","shell.execute_reply":"2025-11-23T10:05:50.759527Z"}},"outputs":[{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"Hello! How can I assist you today?\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"from time import time\nimport pandas as pd\nimport json\n\n# ===== Final Config Parameters =====\nTOPK_INITIAL = 5\nTOPK_EXPANDED = 15\nCONF_THRESHOLD = 0.4   # Force retry if < 0.4\nFAST_MODE_TOKENS = 420  # More tokens for deep reasoning\n\n# ==================================\n# 1Ô∏è‚É£ SAFE RETRIEVAL + CONTEXT\n# ==================================\ndef retrieve(query, k=TOPK_INITIAL):\n    result = collection.query(query_texts=[query], n_results=k, include=[\"distances\"])\n\n    docs_raw = result.get(\"documents\", [[]])\n    metas_raw = result.get(\"metadatas\", [[]])\n    dists_raw = result.get(\"distances\", [[]])\n\n    if not docs_raw or docs_raw[0] is None:\n        return [], [0.0]\n\n    docs = list(zip(docs_raw[0], metas_raw[0]))\n    sims = [(1 - d) if d is not None else 0.5 for d in dists_raw[0]]\n    return docs, sims\n\n\ndef format_context(docs):\n    if not docs:\n        return \"No relevant documents found.\"\n    return \"\\n\\n\".join([f\"[Doc {i+1}] {str(d)[:400]}\" for i, (d, _) in enumerate(docs)])\n\n\ndef safe_preview_text(ans):\n    return ((str(ans) if ans is not None else \"No response generated\")[:150] + \"...\")\n\n# ==================================\n# 2Ô∏è‚É£ AGENT HELPERS (No temp used here)\n# ==================================\ndef generate_clarify(query):\n    return chat(\"If query is unclear, ask ONE follow-up question.\", f\"Query: {query}\\nClarify:\")\n\ndef reformulate_query(query):\n    return chat(\"Convert patient query to medical terminology.\", f\"Original query: {query}\\nReformulate:\")\n\ndef risk_awareness(response):\n    return chat(\"Provide general risk awareness (not advice).\", f\"Response: {response}\")\n\ndef doctor_questions(response):\n    return chat(\"Suggest 1-2 general questions for doctor.\", f\"Response: {response}\")\n\n# ==================================\n# 3Ô∏è‚É£ MAIN AGENTIC RAG FUNCTION\n# ==================================\ndef agentic_rag(query, mode=\"patient\"):\n    max_tokens = FAST_MODE_TOKENS\n    retry_enabled = True  # Retry allowed if low confidence\n\n    # 1. Clarify\n    clarify = generate_clarify(query)\n    if \"?\" in clarify:\n        query = clarify\n\n    # 2. Reformulate\n    med_query = reformulate_query(query)\n\n    # 3. Retrieve docs\n    docs, sims = retrieve(med_query)\n    retrieval_sim = max(sims) if sims else 0.5\n\n    # 4. Generate response\n    sys_prompt = \"Answer using only given medical context. Be accurate and clear.\"\n    user_prompt = f\"Q: {query}\\nContext:\\n{format_context(docs)}\"\n    answer = chat(sys_prompt, user_prompt, max_tokens=max_tokens)  # ‚ùå No temperature\n\n    # 5. Self-evaluate\n    eval_sys = \"Rate JSON {'score':0-1,'needs_retry':bool}\"\n    eval_res = chat(eval_sys, f\"Q: {query}\\nAnswer: {answer}\")\n    try:\n        ev = json.loads(eval_res)\n    except:\n        ev = {\"score\": 0.5, \"needs_retry\": True}\n\n    # 6. Final confidence using new formula\n    llm_conf = ev.get(\"score\", 0.5)\n    final_conf = round(0.5 * llm_conf + 0.5 * retrieval_sim, 2)\n\n    # 7. Retry if needed\n    if retry_enabled and final_conf < CONF_THRESHOLD:\n        docs, sims = retrieve(med_query, TOPK_EXPANDED)\n        answer = chat(sys_prompt, f\"Q: {query}\\nContext:\\n{format_context(docs)}\", max_tokens=max_tokens)\n\n    # 8. Final patient-style response\n    if mode == \"patient\":\n        answer = chat(\n            \"Rewrite in supportive tone. Avoid medical advice. Encourage doctor discussion.\",\n            answer,\n            max_tokens=max_tokens\n        )\n        answer += \"\\n\\n‚ö†Ô∏è \" + risk_awareness(answer)\n        answer += \"\\n\\nü©∫ Suggested questions:\\n- \" + doctor_questions(answer)\n\n    ev[\"final_confidence\"] = final_conf\n    return answer, ev\n\n# ==================================\n# 4Ô∏è‚É£ EVALUATION CODE\n# ==================================\ndef evaluate_system(queries):\n    results = []\n    for q in queries:\n        start = time()\n        ans, ev = agentic_rag(q, mode=\"patient\")\n        elapsed = time() - start\n\n        results.append({\n            \"query\": q,\n            \"confidence_score\": ev.get(\"final_confidence\", 0),\n            \"needed_retry\": ev.get(\"needs_retry\", False),\n            \"response_time_sec\": round(elapsed, 2),\n            \"response_preview\": safe_preview_text(ans)\n        })\n    return results\n\n# ==================================\n# 5Ô∏è‚É£ TEST IT\n# ==================================\ntest_queries = [\n    \"I have high blood pressure and I‚Äôm going for surgery. Should I worry?\",\n    \"I have diabetes and I'm scheduled for cataract surgery. Is it risky?\",\n    \"I have asthma but I often ignore inhalers. Can it affect anesthesia?\",\n    \"I take multiple heart medications. Should I inform my doctor before treatment?\",\n    \"I often skip sugar check-ups. Will it slow recovery after surgery?\"\n]\n\nfast_results = evaluate_system(test_queries)\ndf_fast = pd.DataFrame(fast_results)\n\n# Fix missing values\ndf_fast[\"confidence_score\"] = df_fast[\"confidence_score\"].fillna(0)\ndf_fast[\"needed_retry\"] = df_fast[\"needed_retry\"].fillna(False)\n\nsummary_fast = {\n    \"avg_confidence\": round(df_fast[\"confidence_score\"].mean(), 3),\n    \"retry_rate_%\": round((df_fast[\"needed_retry\"].sum() / len(df_fast)) * 100, 2),\n    \"avg_response_time_sec\": round(df_fast[\"response_time_sec\"].mean(), 2)\n}\n\n# Final output\ndf_fast, summary_fast","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:17:05.636068Z","iopub.execute_input":"2025-11-23T10:17:05.636402Z","iopub.status.idle":"2025-11-23T10:22:39.743933Z","shell.execute_reply.started":"2025-11-23T10:17:05.636378Z","shell.execute_reply":"2025-11-23T10:22:39.743281Z"}},"outputs":[{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"(                                               query  confidence_score  \\\n 0  I have high blood pressure and I‚Äôm going for s...              0.50   \n 1  I have diabetes and I'm scheduled for cataract...              0.50   \n 2  I have asthma but I often ignore inhalers. Can...              0.25   \n 3  I take multiple heart medications. Should I in...              0.50   \n 4  I often skip sugar check-ups. Will it slow rec...              0.25   \n \n    needed_retry  response_time_sec  \\\n 0         False              47.32   \n 1         False              64.06   \n 2          True              67.74   \n 3         False              40.51   \n 4          True             114.45   \n \n                                     response_preview  \n 0  Managing high blood pressure before surgery is...  \n 1  It's absolutely crucial to consider the unique...  \n 2  It's reassuring to know that using an asthma i...  \n 3  Absolutely, it's incredibly important to share...  \n 4  Regular monitoring of your blood sugar levels ...  ,\n {'avg_confidence': 0.4, 'retry_rate_%': 40.0, 'avg_response_time_sec': 66.82})"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"def interactive_chat():\n    print(\"ü©∫ Agentic RAG Medical Assistant (Notebook Mode)\")\n    print(\"Type 'exit' to stop.\\n\")\n    \n    while True:\n        query = input(\"üîé Enter your query: \")  # User types directly in console\n        \n        if query.lower() in [\"exit\", \"quit\", \"stop\"]:\n            print(\"\\nüëã Exiting... Stay healthy!\")\n            break\n        \n        start = time()\n        answer, ev = agentic_rag(query, mode=\"patient\")\n        elapsed = round(time() - start, 2)\n\n        confidence = ev.get(\"final_confidence\", None)\n        retry = ev.get(\"needs_retry\", False)\n\n        print(\"\\nüí¨ Response:\")\n        print(answer)\n        print(f\"\\nüìà Confidence: {confidence}\")\n        print(f\"üîÅ Retry Triggered: {retry}\")\n        print(f\"‚è± Response Time: {elapsed} sec\\n\")\n        print(\"-\" * 80)\n\n# Run the console chat\ninteractive_chat()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T10:27:41.617637Z","iopub.execute_input":"2025-11-23T10:27:41.618371Z","iopub.status.idle":"2025-11-23T10:33:26.929654Z","shell.execute_reply.started":"2025-11-23T10:27:41.618344Z","shell.execute_reply":"2025-11-23T10:33:26.929041Z"}},"outputs":[{"name":"stdout","text":"ü©∫ Agentic RAG Medical Assistant (Notebook Mode)\nType 'exit' to stop.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"üîé Enter your query:  i have a burning sensation in my eyes and high temperature around 40 degree celsius and after few hours i completely lost my sense of smell... what to do now\n"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\nüí¨ Response:\nIt sounds like you might be concerned about some potential symptoms that aren't currently documented. It's really important to pay attention to your health and any changes you notice. If you're experiencing symptoms such as a cough, difficulty breathing, or body aches, I encourage you to discuss these with a healthcare professional. They can provide personalized guidance and help ensure you receive the care you need. Don't hesitate to reach out to your doctor for a thorough assessment. Your health is key, and taking proactive steps by consulting with a medical expert can offer peace of mind and appropriate support.\n\n‚ö†Ô∏è Absolutely, staying aware of your overall health and being proactive about any changes or concerns is crucial. Regular check-ups with healthcare professionals are recommended to monitor your well-being and address any issues early on. This includes keeping track of your physical, mental, and emotional health. If you experience any unusual symptoms, it's wise to consult with a healthcare provider who can offer professional advice tailored to your specific situation. Remember, prevention and early intervention often lead to better outcomes. Always prioritize your health and seek guidance when needed.\n\nü©∫ Suggested questions:\n- 1. What are the common symptoms of flu and how can they be managed at home?\n2. How can I maintain good mental health during stressful times?\n\nüìà Confidence: 0.0\nüîÅ Retry Triggered: False\n‚è± Response Time: 33.04 sec\n\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"üîé Enter your query:  i have a slight headache and running nose what to do \n"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\nüí¨ Response:\nIn situations where you're unable to locate pertinent documents, it's highly recommended to consult with a healthcare provider if you're experiencing symptoms that need immediate attention or clarification. For minor concerns that can typically be managed at home, applying basic self-care strategies might suffice. However, for more complex or concerning health issues, seeking professional medical guidance is crucial. This ensures that any necessary treatments or further diagnostics are provided by qualified medical professionals, helping to address your health needs effectively and safely. Always feel free to discuss your symptoms and concerns openly with your doctor to receive personalized advice tailored to your specific situation.\n\n‚ö†Ô∏è Risk awareness in health situations involves being proactive about your well-being and understanding the potential consequences of various actions. Here are some key points to consider:\n\n1. **Symptom Recognition**: Knowing when a symptom requires immediate medical attention versus when it can be managed at home is crucial. Immediate medical care should be sought for severe symptoms such as chest pain, difficulty breathing, severe bleeding, or sudden changes in mental status.\n\n2. **Documentation**: Keeping records of your health history, medications, allergies, and any previous medical conditions can be invaluable. If you lose or cannot access these documents, try to recall this information from memory or contact your healthcare provider for assistance.\n\n3. **Communication with Healthcare Providers**: Always communicate openly and honestly with your healthcare providers about your symptoms, concerns, and any treatments you are receiving. This helps them provide the most appropriate care and advice.\n\n4. **Self-Care vs. Professional Care**: While self-care measures like rest, hydration, and over-the-counter medication can be effective for minor ailments, more serious conditions often require professional intervention. Over-the-counter treatments may not address underlying issues or could interact negatively with other medications.\n\n5. **Understanding Risks and Benefits**: Before undergoing any medical procedure or treatment, understand the potential risks and benefits. Discussing these with your healthcare provider can help you make informed decisions.\n\n6. **Emergency Preparedness**: Knowing how to respond during emergencies, having an emergency kit ready, and knowing the location of nearby hospitals or clinics can significantly reduce risks in critical situations.\n\n7. **Regular Health Checks**: Regular check-ups and screenings can help detect health issues early, when they are more manageable. This proactive approach can prevent complications and reduce overall health risks.\n\n8. **Health Insurance and Access**: Ensure you have adequate health insurance coverage and know how to access it when needed. Understanding your policy can prevent unexpected financial burdens associated with medical care.\n\n9. **Mental Health Awareness**: Mental health issues can significantly impact physical health. Recognizing signs of stress, anxiety, or depression and seeking help are important steps in maintaining overall health.\n\n10. **Stay Informed**: Keep yourself updated on health news, guidelines, and best practices. Reliable sources of information can help you make informed decisions about your health and the health of those around you.\n\nBy being aware of these aspects, you can better manage your health and navigate through various health-related challenges.\n\nü©∫ Suggested questions:\n- 1. What are the common symptoms that might indicate a need for immediate medical attention, and how can I recognize them?\n2. How can I ensure I maintain good health and prevent potential health issues, especially considering factors like diet, exercise, and regular check-ups?\n\nüìà Confidence: 0.5\nüîÅ Retry Triggered: False\n‚è± Response Time: 60.14 sec\n\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"üîé Enter your query:  exit\n"},{"name":"stdout","text":"\nüëã Exiting... Stay healthy!\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import gradio as gr\n\ndef gradio_interface(user_query):\n    start = time()\n    \n    # Run Fast Agentic RAG\n    answer, ev = agentic_rag(user_query, mode=\"patient\")\n    elapsed = round(time() - start, 2)\n\n    confidence = ev.get(\"final_confidence\", None)\n    retry = ev.get(\"needs_retry\", False)\n\n    return answer, confidence, retry, elapsed\n\n\n# ---------------------------------\n# üñ•Ô∏è Gradio UI Setup\n# ---------------------------------\nwith gr.Blocks() as demo:\n    gr.Markdown(\"\"\"\n    # ü©∫ Agentic RAG Health Support System  \n    *Non-advisory medical information assistant (Portfolio Demo)*  \n    **Features:**\n    - Converts patient queries into medical context\n    - Retrieves relevant context\n    - Self-evaluates responses\n    - Reformulates in patient-friendly mode\n    - Uses retry if confidence is low\n    \"\"\")\n\n    with gr.Row():\n        user_query = gr.Textbox(\n            label=\"üîé Enter your question\",\n            placeholder=\"e.g., I have diabetes and I'm having eye surgery soon...\",\n            lines=3\n        )\n\n    submit_button = gr.Button(\"üöÄ Get Response\")\n\n    with gr.Row():\n        answer_output = gr.Textbox(label=\"üí¨ AI Response\", lines=7)\n    \n    with gr.Row():\n        confidence_output = gr.Number(label=\"üìà Confidence Score\")\n        retry_output = gr.Checkbox(label=\"üîÅ Retry Triggered?\")\n        time_output = gr.Number(label=\"‚è± Response Time (sec)\")\n\n    submit_button.click(\n        fn=gradio_interface,\n        inputs=user_query,\n        outputs=[answer_output, confidence_output, retry_output, time_output]\n    )\n\ndemo.launch()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}