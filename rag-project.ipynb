{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":799923,"sourceType":"datasetVersion","datasetId":374},{"sourceId":1043323,"sourceType":"datasetVersion","datasetId":576263},{"sourceId":2931845,"sourceType":"datasetVersion","datasetId":1797388},{"sourceId":9338941,"sourceType":"datasetVersion","datasetId":5659416},{"sourceId":69160,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":57690,"modelId":79606}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:28:51.454658Z","iopub.execute_input":"2025-11-11T10:28:51.455283Z","iopub.status.idle":"2025-11-11T10:28:51.466880Z","shell.execute_reply.started":"2025-11-11T10:28:51.455256Z","shell.execute_reply":"2025-11-11T10:28:51.466183Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/medquad-medical-question-answer-for-ai-research/medquad.csv\n/kaggle/input/stanford-question-answering-dataset/train-v1.1.json\n/kaggle/input/stanford-question-answering-dataset/dev-v1.1.json\n/kaggle/input/qwen2/transformers/7b-instruct/1/model.safetensors.index.json\n/kaggle/input/qwen2/transformers/7b-instruct/1/model-00003-of-00004.safetensors\n/kaggle/input/qwen2/transformers/7b-instruct/1/config.json\n/kaggle/input/qwen2/transformers/7b-instruct/1/merges.txt\n/kaggle/input/qwen2/transformers/7b-instruct/1/LICENSE\n/kaggle/input/qwen2/transformers/7b-instruct/1/model-00001-of-00004.safetensors\n/kaggle/input/qwen2/transformers/7b-instruct/1/README.md\n/kaggle/input/qwen2/transformers/7b-instruct/1/tokenizer.json\n/kaggle/input/qwen2/transformers/7b-instruct/1/vocab.json\n/kaggle/input/qwen2/transformers/7b-instruct/1/tokenizer_config.json\n/kaggle/input/qwen2/transformers/7b-instruct/1/model-00004-of-00004.safetensors\n/kaggle/input/qwen2/transformers/7b-instruct/1/model-00002-of-00004.safetensors\n/kaggle/input/qwen2/transformers/7b-instruct/1/generation_config.json\n/kaggle/input/amazon-questionanswer-dataset/multi_questions.csv\n/kaggle/input/amazon-questionanswer-dataset/single_qna.csv\n/kaggle/input/amazon-questionanswer-dataset/multi_answers.csv\n/kaggle/input/cisi-a-dataset-for-information-retrieval/CISI.REL\n/kaggle/input/cisi-a-dataset-for-information-retrieval/CISI.ALL\n/kaggle/input/cisi-a-dataset-for-information-retrieval/CISI.QRY\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install --quiet transformers sentence-transformers pinecone tqdm accelerate\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install protobuf==3.20.3 --quiet --force-reinstall\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\npinecone_api = user_secrets.get_secret(\"pinecone_api_key\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:28:31.728990Z","iopub.execute_input":"2025-11-11T10:28:31.729772Z","iopub.status.idle":"2025-11-11T10:28:31.765857Z","shell.execute_reply.started":"2025-11-11T10:28:31.729744Z","shell.execute_reply":"2025-11-11T10:28:31.765343Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nimport json\nimport pinecone\nimport torch\nfrom tqdm import tqdm\nfrom transformers import AutoTokenizer, pipeline\nfrom sentence_transformers import SentenceTransformer\nfrom pinecone import Pinecone, ServerlessSpec\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom sklearn.decomposition import PCA","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:35:55.125595Z","iopub.execute_input":"2025-11-11T14:35:55.125769Z","iopub.status.idle":"2025-11-11T14:35:56.723938Z","shell.execute_reply.started":"2025-11-11T14:35:55.125753Z","shell.execute_reply":"2025-11-11T14:35:56.722804Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/3451835780.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpinecone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pinecone'"],"ename":"ModuleNotFoundError","evalue":"No module named 'pinecone'","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"# Initialize Pinecone client\npc = Pinecone(api_key=pinecone_api)\n\nindex_name = \"rag-project\"\ndimension = 768  # for all-mpnet-base-v2 embeddings\nmetric = \"cosine\"\n\n# Check if index exists\nexisting_indexes = [i[\"name\"] for i in pc.list_indexes()]\nprint(\"Existing indexes:\", existing_indexes)\n\nif index_name not in existing_indexes:\n    print(\"Creating index...\")\n    pc.create_index(\n        name=index_name,\n        dimension=dimension,\n        metric=metric,\n        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n    )\n\n# Connect to the index\nindex = pc.Index(index_name)\nprint(f\"Connected to Pinecone index: {index_name}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T13:25:05.322961Z","iopub.execute_input":"2025-11-11T13:25:05.323268Z","iopub.status.idle":"2025-11-11T13:25:08.260407Z","shell.execute_reply.started":"2025-11-11T13:25:05.323244Z","shell.execute_reply":"2025-11-11T13:25:08.259701Z"}},"outputs":[{"name":"stdout","text":"Existing indexes: ['rag-project']\nConnected to Pinecone index: rag-project\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"# --- MedQuad (Medical QA) ---\nmedquad = pd.read_csv(\"/kaggle/input/medquad-medical-question-answer-for-ai-research/medquad.csv\")\nmedquad_docs = medquad['question'].tolist()\nmedquad_answers = medquad['answer'].tolist()\nmedquad_domain = ['Medical'] * len(medquad_docs)\n\n# --- Amazon QA (E-commerce) ---\namazon_multi_q = pd.read_csv(\"/kaggle/input/amazon-questionanswer-dataset/multi_questions.csv\")\namazon_single = pd.read_csv(\"/kaggle/input/amazon-questionanswer-dataset/single_qna.csv\")\namazon_multi_a = pd.read_csv(\"/kaggle/input/amazon-questionanswer-dataset/multi_answers.csv\")\n\namazon_docs = (\n    amazon_multi_q['QuestionText'].tolist() +\n    amazon_single['Question'].tolist() +\n    amazon_multi_a['AnswerText'].tolist()\n)\namazon_answers = amazon_single['Answer'].tolist() + amazon_multi_a['AnswerText'].tolist()\namazon_domain = ['E-commerce'] * len(amazon_docs)\n\n# --- SQuAD (General QA) ---\ndef load_squad(path):\n    with open(path) as f:\n        data = json.load(f)\n    docs, answers = [], []\n    for article in data['data']:\n        for paragraph in article['paragraphs']:\n            for qa in paragraph['qas']:\n                docs.append(qa['question'])\n                answers.append(qa['answers'][0]['text'] if qa['answers'] else \"\")\n    return docs, answers\n\nsquad_docs, squad_answers = load_squad(\"/kaggle/input/stanford-question-answering-dataset/train-v1.1.json\")\nsquad_domain = ['General'] * len(squad_docs)\n\n# --- CISI (Information Retrieval) ---\nwith open(\"/kaggle/input/cisi-a-dataset-for-information-retrieval/CISI.ALL\", \"r\") as f:\n    cisi_docs = [line.strip() for line in f.readlines() if line.strip()]\ncisi_answers = [\"\"] * len(cisi_docs)\ncisi_domain = ['IR'] * len(cisi_docs)\n\n# --- Combine all ---\nall_docs = medquad_docs + amazon_docs + squad_docs + cisi_docs\nall_answers = medquad_answers + amazon_answers + squad_answers + cisi_answers\nall_domains = medquad_domain + amazon_domain + squad_domain + cisi_domain\n\nprint(f\"âœ… Total documents: {len(all_docs)}\")\nprint(f\"âœ… Domains: {set(all_domains)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:48:19.049832Z","iopub.execute_input":"2025-11-11T10:48:19.050636Z","iopub.status.idle":"2025-11-11T10:48:41.513982Z","shell.execute_reply.started":"2025-11-11T10:48:19.050607Z","shell.execute_reply":"2025-11-11T10:48:41.513124Z"}},"outputs":[{"name":"stdout","text":"Total documents: 5801972\nTotal answers: 5629355\nDomains: {'Medical', 'E-commerce', 'IR', 'General'}\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Sample only 10% (adjustable)\nsample_fraction = 0.1\nsample_indices = random.sample(range(len(all_docs)), int(len(all_docs) * sample_fraction))\nsampled_docs = [all_docs[i] for i in sample_indices]\nsampled_answers = [all_answers[i] for i in sample_indices]\nsampled_domains = [all_domains[i] for i in sample_indices]\n\nprint(f\"ðŸ§© Sampled {len(sampled_docs)} docs ({sample_fraction*100:.0f}%)\")\n\n# Embed using smaller model\nmodel = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\nembeddings = model.encode(sampled_docs, show_progress_bar=True, batch_size=64)\n\n# PCA to compress from 384 â†’ 256 dims\npca = PCA(n_components=256)\nembeddings_pca = pca.fit_transform(embeddings)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def chunks(lst, n):\n    for i in range(0, len(lst), n):\n        yield lst[i:i + n]\n\nbatch_size = 100\nfor batch_ids, batch_embeds, batch_docs, batch_answers, batch_domains in tqdm(\n    zip(\n        chunks(range(len(embeddings_pca)), batch_size),\n        chunks(embeddings_pca, batch_size),\n        chunks(sampled_docs, batch_size),\n        chunks(sampled_answers, batch_size),\n        chunks(sampled_domains, batch_size)\n    ),\n    total=len(embeddings_pca) // batch_size\n):\n    vectors = [\n        {\n            \"id\": f\"doc-{i}\",\n            \"values\": emb,\n            \"metadata\": {\n                \"text\": doc,\n                \"answer\": ans,\n                \"domain\": domain\n            }\n        }\n        for i, emb, doc, ans, domain in zip(batch_ids, batch_embeds, batch_docs, batch_answers, batch_domains)\n    ]\n    index.upsert(vectors=vectors)\n\nprint(\"âœ… All embeddings upserted successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:02:41.220425Z","iopub.execute_input":"2025-11-11T11:02:41.221034Z"}},"outputs":[{"name":"stderr","text":" 11%|â–ˆ         | 9585/90656 [1:21:13<10:57:47,  2.05it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"gen_model_path = \"/kaggle/input/qwen2/transformers/7b-instruct/1\"\ngen_pipe = pipeline(\n    \"text-generation\",\n    model=gen_model_path,\n    device=0,       # GPU=0, CPU=-1\n    max_new_tokens=150,\n    do_sample=True,\n    temperature=0.7,\n    top_p=0.9\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def rag_answer_self_consistent(query, top_k=5, num_samples=5):\n    # 1ï¸âƒ£ Embed query\n    query_vec = embed_model.encode(query).tolist()\n    \n    # 2ï¸âƒ£ Retrieve from Pinecone\n    results = index.query(vector=query_vec, top_k=top_k)\n    context = \" \".join([match.id for match in results.matches])\n    \n    # 3ï¸âƒ£ Generate multiple answers\n    prompt = f\"Answer the question based on context:\\nQuestion: {query}\\nContext: {context}\"\n    answers = [gen_pipe(prompt)[0]['generated_text'] for _ in range(num_samples)]\n    \n    # 4ï¸âƒ£ Majority vote for final answer\n    most_common = Counter(answers).most_common(1)[0][0]\n    return most_common, answers","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_f1(pred, gold):\n    pred_tokens = pred.split()\n    gold_tokens = gold.split()\n    common = set(pred_tokens) & set(gold_tokens)\n    if len(common) == 0:\n        return 0.0\n    precision = len(common) / len(pred_tokens)\n    recall = len(common) / len(gold_tokens)\n    if precision + recall == 0:\n        return 0.0\n    f1 = 2 * (precision * recall) / (precision + recall)\n    return f1\n\ndef exact_match(pred, gold):\n    return int(pred.strip().lower() == gold.strip().lower())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"domain_metrics = {}\n\nfor domain in set(all_domains):\n    print(f\"Evaluating domain: {domain}\")\n    indices = [i for i, d in enumerate(all_domains) if d==domain and all_answers[i]!=\"\"]\n    em_scores, f1_scores, self_consistency = [], [], []\n    \n    for idx in tqdm(indices):\n        query = all_docs[idx]\n        gold = all_answers[idx]\n        \n        pred, all_preds = rag_answer_self_consistent(query, top_k=5, num_samples=5)\n        em_scores.append(exact_match(pred, gold))\n        f1_scores.append(compute_f1(pred, gold))\n        \n        # Self-consistency: fraction of identical answers\n        counts = Counter(all_preds)\n        sc = counts.most_common(1)[0][1] / len(all_preds)\n        self_consistency.append(sc)\n    \n    domain_metrics[domain] = {\n        \"ExactMatch\": sum(em_scores)/len(em_scores)*100 if em_scores else None,\n        \"F1\": sum(f1_scores)/len(f1_scores)*100 if f1_scores else None,\n        \"SelfConsistency\": sum(self_consistency)/len(self_consistency)*100 if self_consistency else None,\n        \"NumQueries\": len(indices)\n    }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for domain, metrics in domain_metrics.items():\n    print(f\"\\nDomain: {domain}\")\n    print(f\"NumQueries: {metrics['NumQueries']}\")\n    print(f\"Exact Match (%): {metrics['ExactMatch']}\")\n    print(f\"F1 (%): {metrics['F1']}\")\n    print(f\"Self-Consistency (%): {metrics['SelfConsistency']}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}